% Simple Beamer Template
\documentclass{beamer}
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{footline}[page number]


\title{Causal inference in the latent space of convergent cross-mapping}
\author{IA pour la Science}
\date{December $19^\text{th}$, 2025}

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{The principle of causal inference for latent spaces}
Methods of causal inference and Structural Causal Models assume that there exist
\begin{enumerate}
\item explainable, labeled measurements represented as variables,
\item a computational graph in which each vertex corresponds to a single variable.
\end{enumerate}

\bigskip
In AI, data have excessively high dimensionality. Causality can be observed only in a low-dimensional latent space. The model that maps the data into this space is non-interpretable. The problem is therefore to identify causality in the latent space. This causality
\begin{enumerate}
\item learns the relationship between source and target variables in a reduced-dimensional space,
\item explains the observable variables by back-propagation for the source and by forward-propagation for the target.
\end{enumerate}

\bigskip
\textit{Significance of this principle:} it introduces a new method to dimensionality reduction.
\end{frame}


%=============================================
%\begin{frame}{The principle of causal inference for latent spaces}
%The methods of Causal Inference and the Structural Causal Models assume that there 
%\begin{enumerate}
%\item explainable labeled measurements as variables,
%\item the computational graph with a single variable as a vertex.
%\end{enumerate}
%
%\bigskip
%In Machine Learning, the data have excessive dimensionality. The causality could be observed only in a low-dimensional latent space. The model that maps into this space is non-interpretable. The problem is to find a causality in the latent space. This causality 
%\begin{enumerate}
%\item learns the connection between source and target variables in the space of  reduced dimensionality,
%\item explains the observable variables by back-propagation for the source and by forward-propagation for the target.
%\end{enumerate}
%
%\bigskip
%Significance of this principle: it introduces a new way of dimensionality reduction.
%\end{frame}
%=============================================
%=============================================
\begin{frame}{The problem of causal inference for latent spaces}

A set of time series $x_t$ and $y_t$ is given, generated by a single observable dynamical system.
They are represented  %
%\footnote{For multivariate time series the tensors $\underline{X},\underline{Y}$ will be flatten to the matrices. See the time-delay embedding for the Singular Spectrum Analysis below.} 
as time-delay matrices $X$ and $Y$. The problem is to forecast the vector $y_{t+1}$.

\bigskip
The forecasting model~$f:t \mapsto y\ni Y$ assumes that~$X$ and~$Y$ are mapped by orthogonal operators~$U$ and~$V$ into low-dimensional manifolds. The components of the resulting vectors are independent. The goal is to find the elements of the linear alignment~$\Lambda$ that express causality in some components of the time series $x_t$ and $y_t$.

\bigskip
Denote by $\hat{Y} = F(X)$ the forecast~$\hat{Y}$ obtained via the linear operator~$F$. To approximate the target~$Y$, make the singular value decomposition of the operator
\[
F = U \Lambda V^\mathsf{T}
\]
and select the components of the diagonal matrix~$\Lambda$ that express the causality.
\end{frame}

%\begin{frame}{The problem of causal inference for latent spaces}
%
%There given a set of time series $x_t, y_t$, generated by a single observable dynamic system.
%They represented %
%%\footnote{For multivariate time series the tensors $\underline{X},\underline{Y}$ will be flatten to the matrices. See the time-delay embedding for the Singular Spectrum Analysis below.} 
%as the time-delay matrices $X$, $Y$. One have to forecast an incoming vector $y_{t+1}$ at the time $t$. 
%
%\bigskip
%The forecasting model~$f:t\mapsto y$ assumes that the phase trajectory map by orthogonal operators~$U,V$  into low-dimensional manifolds. The components of the vectors~$u,v$ are independent. One has to find elements of the linear alignment~$\Lambda$ that expresses the causality in some components of the time series $x_t,y_t$.
%
%\bigskip
%Denote by $\hat{Y} = F(X)$ the linear operator~$F$ and forecast~$\hat{Y}$. To approximate the matrix $Y$ with the singular values decomposition of the operator
%\[F = U\Lambda V^\mathsf{T},\]
%select the components of the diagonal matrix~$\Lambda$ that express the causality.
%\end{frame}
%=============================================
%=============================================

\end{document}