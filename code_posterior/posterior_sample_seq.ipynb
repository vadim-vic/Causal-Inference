{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Printout parameters of each neuron in a multi-layer neural network after each epoch",
   "id": "acb620554dfb8a2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T12:02:33.860712Z",
     "start_time": "2026-01-18T12:02:31.895092Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Dataset: 100 samples, 8 features\n",
    "X = torch.randn(100, 8)\n",
    "y = torch.randint(0, 2, (100,))\n",
    "\n",
    "loader = DataLoader(TensorDataset(X, y), batch_size=16, shuffle=True)\n",
    "\n",
    "# Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 4),   # 4 neurons\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4, 2)    # 2 neurons\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:02:37.013397Z",
     "start_time": "2026-01-18T12:02:36.994772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_linear_params_by_neuron(model, epoch):\n",
    "    print(f\"\\n===== Epoch {epoch} =====\")\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            print(f\"\\nLayer: {name} ({module.in_features} → {module.out_features})\")\n",
    "\n",
    "            W = module.weight.detach()\n",
    "            b = module.bias.detach() if module.bias is not None else None\n",
    "\n",
    "            for i in range(W.size(0)):  # out_features = neurons\n",
    "                print(f\"  Neuron {i}:\")\n",
    "                print(f\"    weights: {W[i].tolist()}\")\n",
    "                if b is not None:\n",
    "                    print(f\"    bias: {b[i].item()}\")\n"
   ],
   "id": "c99e7999f72ab8d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T12:02:41.090630Z",
     "start_time": "2026-01-18T12:02:39.952777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for xb, yb in loader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print neuron parameters AFTER the epoch update\n",
    "    print_linear_params_by_neuron(model, epoch)"
   ],
   "id": "c133a29628052d7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Epoch 0 =====\n",
      "\n",
      "Layer: 0 (8 → 4)\n",
      "  Neuron 0:\n",
      "    weights: [0.2962336540222168, 0.33845847845077515, 0.31499844789505005, 0.24144454300403595, 0.24830344319343567, -0.04581242427229881, -0.2696641981601715, -0.1312015801668167]\n",
      "    bias: -0.34424811601638794\n",
      "  Neuron 1:\n",
      "    weights: [-0.04334290325641632, -0.18978939950466156, 0.18213173747062683, 0.12346253544092178, 0.05755989998579025, 0.07860177010297775, 0.3078535199165344, 0.1299828737974167]\n",
      "    bias: 0.2384561449289322\n",
      "  Neuron 2:\n",
      "    weights: [-0.2737734019756317, -0.24314728379249573, 0.1518600881099701, 0.07654411345720291, 0.15166951715946198, -0.33928361535072327, -0.32035118341445923, 0.21334390342235565]\n",
      "    bias: 0.29439207911491394\n",
      "  Neuron 3:\n",
      "    weights: [0.20186041295528412, -0.310230016708374, 0.15634950995445251, -0.2799144983291626, 0.2537148594856262, 0.06967966258525848, 0.3274569511413574, -0.3479851484298706]\n",
      "    bias: 0.2110438346862793\n",
      "\n",
      "Layer: 2 (4 → 2)\n",
      "  Neuron 0:\n",
      "    weights: [0.3126909136772156, -0.41027316451072693, 0.30438199639320374, -0.43170493841171265]\n",
      "    bias: -0.2119818925857544\n",
      "  Neuron 1:\n",
      "    weights: [0.13142485916614532, -0.3383798897266388, -0.14107291400432587, 0.04816583916544914]\n",
      "    bias: -0.06371956318616867\n",
      "\n",
      "===== Epoch 1 =====\n",
      "\n",
      "Layer: 0 (8 → 4)\n",
      "  Neuron 0:\n",
      "    weights: [0.29452571272850037, 0.3325425088405609, 0.3153083026409149, 0.24742630124092102, 0.2499697506427765, -0.04570634290575981, -0.26756614446640015, -0.13178430497646332]\n",
      "    bias: -0.34279492497444153\n",
      "  Neuron 1:\n",
      "    weights: [-0.04565612971782684, -0.1891947239637375, 0.18221230804920197, 0.12176929414272308, 0.05729936435818672, 0.07603660225868225, 0.3064957559108734, 0.13058923184871674]\n",
      "    bias: 0.2377869039773941\n",
      "  Neuron 2:\n",
      "    weights: [-0.24970348179340363, -0.2478741556406021, 0.16514691710472107, 0.10034727305173874, 0.1460094451904297, -0.33998826146125793, -0.3154670000076294, 0.19357822835445404]\n",
      "    bias: 0.2788085639476776\n",
      "  Neuron 3:\n",
      "    weights: [0.19272930920124054, -0.29762712121009827, 0.16609254479408264, -0.28371718525886536, 0.2388383001089096, 0.04730495065450668, 0.3186447024345398, -0.34432661533355713]\n",
      "    bias: 0.2055174857378006\n",
      "\n",
      "Layer: 2 (4 → 2)\n",
      "  Neuron 0:\n",
      "    weights: [0.3045758008956909, -0.399335116147995, 0.27562233805656433, -0.4022086560726166]\n",
      "    bias: -0.23068460822105408\n",
      "  Neuron 1:\n",
      "    weights: [0.13953998684883118, -0.3493179380893707, -0.11231324076652527, 0.01866954378783703]\n",
      "    bias: -0.045016851276159286\n",
      "\n",
      "===== Epoch 2 =====\n",
      "\n",
      "Layer: 0 (8 → 4)\n",
      "  Neuron 0:\n",
      "    weights: [0.29207372665405273, 0.3254576325416565, 0.31441155076026917, 0.25121837854385376, 0.25130292773246765, -0.04800121486186981, -0.2669300138950348, -0.1338309943675995]\n",
      "    bias: -0.34262579679489136\n",
      "  Neuron 1:\n",
      "    weights: [-0.04627269133925438, -0.18839333951473236, 0.18196943402290344, 0.12099158763885498, 0.05744992941617966, 0.0735824778676033, 0.3063293397426605, 0.13052420318126678]\n",
      "    bias: 0.23710960149765015\n",
      "  Neuron 2:\n",
      "    weights: [-0.23571795225143433, -0.24416308104991913, 0.16565820574760437, 0.12358111888170242, 0.14129410684108734, -0.33324602246284485, -0.31951770186424255, 0.18383748829364777]\n",
      "    bias: 0.27028536796569824\n",
      "  Neuron 3:\n",
      "    weights: [0.18280819058418274, -0.28711163997650146, 0.17858858406543732, -0.2936991751194, 0.22657473385334015, 0.022983144968748093, 0.31410449743270874, -0.33906278014183044]\n",
      "    bias: 0.20455586910247803\n",
      "\n",
      "Layer: 2 (4 → 2)\n",
      "  Neuron 0:\n",
      "    weights: [0.29297223687171936, -0.40073418617248535, 0.2553614377975464, -0.3860691487789154]\n",
      "    bias: -0.2545202970504761\n",
      "  Neuron 1:\n",
      "    weights: [0.15114356577396393, -0.34791886806488037, -0.09205234795808792, 0.0025300420820713043]\n",
      "    bias: -0.021181169897317886\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
